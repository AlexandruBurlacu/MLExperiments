{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20 Newsgroups & Logistic Regression\n",
    "\n",
    "This notebook is a slightly enhanced demo used during my presentation during the first, closed-beta Data Science Community meetup that took place on <br> 16 <sup>th</sup> of January 2017.\n",
    "\n",
    "Here's shown how to use scikit-learn's Logistic Regression, and SGDClassifier (that is a more robust implementation of LR, mainly used for large datasets).\n",
    "\n",
    "---\n",
    "\n",
    "The used dataset is 20 Newsgroups, pre-vectorized using TF-IDF algorithm.\n",
    "\n",
    "I've used a 5-fold cross validation scheme and Grid Search for hyperparameter tuning.\n",
    "\n",
    "Also to get higher accuracy, feature vectors were scaled and normalized.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexburlacu/Documents/Projects/MLExperiments/machine-learning-and-a-bit-of-data-science/.venv/local/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import linear_model, preprocessing, cross_validation, datasets\n",
    "import cPickle as cpk\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Global variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_FILE_PATH = \"../tmp/models/lr.pkl\"\n",
    "SGD_FILE_PATH = \"../tmp/models/sgd.pkl\"\n",
    "LR_OP_FILE_PATH = \"../tmp/models/optimized_lr.pkl\"\n",
    "SGD_OP_FILE_PATH = \"../tmp/models/optimized_sgd.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded in 26.1854040623 seconds\n",
      "-------------------------------------------------------------------------------\n",
      "Number of documents in the dataset: 11314\n",
      "Size of the feature vector of a document: 130107\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "news = datasets.fetch_20newsgroups_vectorized()\n",
    "print(\"Data loaded in {0} seconds\".format(time() - start))\n",
    "print(\"-------------------------------------------------------------------------------\")\n",
    "\n",
    "X = news.data\n",
    "y = news.target\n",
    "\n",
    "# _ = [print(topic) for topic in news.target_names] # you may uncoment this to see the topics\n",
    "\n",
    "print(\"Number of documents in the dataset: {0}\".format(*X.shape))\n",
    "print(\"Size of the feature vector of a document: {1}\".format(*X.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some utility functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_str_repr(label):\n",
    "    return news.target_names[label]\n",
    "\n",
    "def formated_print(model_name, acc):\n",
    "    pretty_stat = \"Accuracy of the {0} model is {1}.\".format(model_name, acc)\n",
    "    print(pretty_stat)\n",
    "    \n",
    "def train_estimator(estimator, features):\n",
    "    train, _ = next(iter(kfcv))\n",
    "    estimator.fit(features[train], y[train])\n",
    "    return estimator\n",
    "\n",
    "def save_estimator(estimator, filename):\n",
    "    \"\"\"\n",
    "        Note that it is recomended to use '.pkl' or '.model' file extension.\n",
    "        \n",
    "        Why? Because I want so.\n",
    "        ;)\n",
    "    \"\"\"\n",
    "    with open(filename, \"wb\") as fp:\n",
    "        cpk.dump(estimator, fp)\n",
    "\n",
    "def load_estimator(filename):\n",
    "        with open(filename, \"rb\") as fp:\n",
    "            return cpk.load(fp)\n",
    "\n",
    "def load_or_train(estimator, feature_set, filename):\n",
    "    if not os.path.exists(filename):\n",
    "        print(\"Training...\")\n",
    "        start = time()\n",
    "        estimator = train_estimator(estimator, feature_set)\n",
    "        print(\"Trained in {0} seconds.\".format(time() - start))\n",
    "        print(\"-------------------------------------------------------------------------------\")\n",
    "        print(\"Saving...\")\n",
    "        start = time()\n",
    "        save_estimator(estimator, filename)\n",
    "        print(\"Saved in {0} seconds.\".format(time() - start))\n",
    "    else:\n",
    "        print(\"Loading...\")\n",
    "        start = time()\n",
    "        estimator = load_estimator(filename)\n",
    "        print(\"Loaded in {0} seconds.\".format(time() - start))\n",
    "        \n",
    "    return estimator\n",
    "        \n",
    "def evaluate_estimator(estimator, features):\n",
    "    print(\"Evaluating model's accuracy...\")\n",
    "    start = time()\n",
    "    score = np.mean(cross_validation.cross_val_score(estimator, features, y, cv = kfcv, n_jobs = 4))\n",
    "    print(\"Evaluation done in {0} seconds\".format(time() - start))\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature vector normalization and scaling**\n",
    "\n",
    "Due to the fact that the vectors are sparse, we must scale them just by the standard variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "__X = preprocessing.scale(X, with_mean = False)\n",
    "X_new = preprocessing.normalize(__X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5 Fold cross validation**\n",
    "\n",
    "In order to get more objective results, I have used a 5 fold cross validation scheme, with feature-target pairs shuffling. Because of it, it is now possible to get an averaged result from 5 model evaluations, with training and testing on different portions of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfcv = cross_validation.KFold(len(y), n_folds = 5, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estimators with default parameters**\n",
    "\n",
    "Almost default, in order to speed up the training process I changed the number of workers from 1 to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = linear_model.SGDClassifier(n_jobs = 3)\n",
    "lr = linear_model.LogisticRegression(n_jobs = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy benchmark for default estimators**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexburlacu/Documents/Projects/MLExperiments/machine-learning-and-a-bit-of-data-science/.venv/local/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 3.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained in 13.4839808941 seconds.\n",
      "-------------------------------------------------------------------------------\n",
      "Saving...\n",
      "Saved in 1.54520487785 seconds.\n"
     ]
    }
   ],
   "source": [
    "lr = load_or_train(lr, X, LR_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model's accuracy...\n",
      "Evaluation done in 47.4883239269 seconds\n",
      "-------------------------------------------------------------------------------\n",
      "Accuracy of the Linear Regression model is 0.796623887995.\n"
     ]
    }
   ],
   "source": [
    "mean_acc = evaluate_estimator(lr, X)\n",
    "\n",
    "formated_print(\"Linear Regression\", mean_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SGD Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexburlacu/Documents/Projects/MLExperiments/machine-learning-and-a-bit-of-data-science/.venv/local/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained in 0.661247968674 seconds.\n",
      "-------------------------------------------------------------------------------\n",
      "Saving...\n",
      "Saved in 2.02776503563 seconds.\n"
     ]
    }
   ],
   "source": [
    "sgd = load_or_train(sgd, X, SGD_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model's accuracy...\n",
      "Evaluation done in 3.21923995018 seconds\n",
      "-------------------------------------------------------------------------------\n",
      "Accuracy of the Stochastic Gradient Descent model is 0.872371479375.\n"
     ]
    }
   ],
   "source": [
    "mean_acc = evaluate_estimator(sgd, X)\n",
    "\n",
    "formated_print(\"Stochastic Gradient Descent\", mean_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimized estimators**\n",
    "\n",
    "After playing around with Grid Search hyperparameter optimizer, I've found the below near optimial configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_op = linear_model.SGDClassifier(n_iter = 25, alpha = 0.00005, n_jobs = 3)\n",
    "lr_op = linear_model.LogisticRegression(max_iter = 500, C = 3593.8136638046258, n_jobs = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy benchmark for optimized models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Trained in 17.5047140121 seconds.\n",
      "-------------------------------------------------------------------------------\n",
      "Saving...\n",
      "Saved in 1.66693496704 seconds.\n"
     ]
    }
   ],
   "source": [
    "lr_op = load_or_train(lr_op, X_new, LR_OP_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model's accuracy...\n",
      "Evaluation done in 57.7978448868 seconds\n",
      "-------------------------------------------------------------------------------\n",
      "Accuracy of the Optimized Linear Regression model is 0.919746016043.\n"
     ]
    }
   ],
   "source": [
    "mean_acc = evaluate_estimator(lr_op, X_new)\n",
    "\n",
    "formated_print(\"Optimized Linear Regression\", mean_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SGD Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexburlacu/Documents/Projects/MLExperiments/machine-learning-and-a-bit-of-data-science/.venv/local/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained in 2.50821805 seconds.\n",
      "-------------------------------------------------------------------------------\n",
      "Saving...\n",
      "Saved in 1.86658596992 seconds.\n"
     ]
    }
   ],
   "source": [
    "sgd_op = load_or_train(sgd_op, X_new, SGD_OP_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model's accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexburlacu/Documents/Projects/MLExperiments/machine-learning-and-a-bit-of-data-science/.venv/local/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/alexburlacu/Documents/Projects/MLExperiments/machine-learning-and-a-bit-of-data-science/.venv/local/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/alexburlacu/Documents/Projects/MLExperiments/machine-learning-and-a-bit-of-data-science/.venv/local/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/alexburlacu/Documents/Projects/MLExperiments/machine-learning-and-a-bit-of-data-science/.venv/local/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/alexburlacu/Documents/Projects/MLExperiments/machine-learning-and-a-bit-of-data-science/.venv/local/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation done in 12.5524609089 seconds\n",
      "-------------------------------------------------------------------------------\n",
      "Accuracy of the Optimized Stochastic Gradient Descent model is 0.922662889297.\n"
     ]
    }
   ],
   "source": [
    "mean_acc = evaluate_estimator(sgd_op, X_new)\n",
    "\n",
    "formated_print(\"Optimized Stochastic Gradient Descent\", mean_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "From all the evaluations done above I can conclude the following 2 things:\n",
    "- Data preparation, in this case, scaling and normalizing feature vectors is extremely important and leads to major accuracy improvements.\n",
    "- SGD Classifier is much faster than Logistic Regression while the accuracy is on par or slightly better, so it is preferable when working with big datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
